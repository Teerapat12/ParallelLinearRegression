{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to demonstrate how we can use parallel processing to combine with machine learning so make the computation run faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Introduction</li>\n",
    "<li>Procedure</li>\n",
    "<li>Result</li>\n",
    "<li>Conclusion</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, linear regression is an approach for modeling the relationship between a scalar dependent variable y and one or more explanatory variables (or independent variables) denoted X.The relationships are modeled using linear predictor functions whose unknown model parameters are estimated from the data. Such models are called linear models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.ytimg.com/vi/zPG4NjIkCjc/maxresdefault.jpg\" height=\"650\" width=\"650\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training the data, if data size of data is very large, training might take very long time. Imagine having to train PetaBye size of files. In this project, I will try to use parallel processing technique to help speeding up the time need to train a model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Data</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset come from https://www.kaggle.com/c/house-prices-advanced-regression-techniques. The data contain a lot of features. In this experiment, I already extract features that has high colleration with the output which is \"SalePrice\". The goal is to predict the price of a house given house properties by using Linear Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('train.csv')\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Procedure</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some procedure in fitting a line to a dataset. The steps are as follow :\n",
    "<ul>\n",
    "<li>Preprocessing (Clean data)</li>\n",
    "<li>Load Data into Memory to process</li>\n",
    "<li>Finding Optimal Weight (Normal Equation)</li>\n",
    "<li>Evaluation using validate set</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing</h3>\n",
    "Here we need to clean the data. Cleaning data can range from dealing the noise to feature scaling. This will be done before loading the data into Java file. The remaining features are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>856</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1786</td>\n",
       "      <td>2</td>\n",
       "      <td>920</td>\n",
       "      <td>2</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1717</td>\n",
       "      <td>3</td>\n",
       "      <td>756</td>\n",
       "      <td>1</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2198</td>\n",
       "      <td>3</td>\n",
       "      <td>1145</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OverallQual  GrLivArea  GarageCars  TotalBsmtSF  FullBath  YearBuilt\n",
       "0            7       1710           2          856         2       2003\n",
       "1            6       1262           2         1262         2       1976\n",
       "2            7       1786           2          920         2       2001\n",
       "3            7       1717           3          756         1       1915\n",
       "4            8       2198           3         1145         2       2000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "dataset[cols].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below also show example of SalePrice of the first five house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice\n",
       "0     208500\n",
       "1     181500\n",
       "2     223500\n",
       "3     140000\n",
       "4     250000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = ['SalePrice']\n",
    "dataset[target].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Loading the Data</h3>\n",
    "We will load data into Java to calculate optimal weights best fitting the data. Here, I had seperate the file into 4 parts.\n",
    "In sequential, we will need to read file by file. In contrast, parallel version will be able to read all of them consequently. Because this step takes a lot of time, parallel version speed up is very high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finding Optimal Weights</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before finding optimal weights, let's explore how we will predict the price first. We will first construct a matrix X. Each row of the matrix will be a detail of one house, while column represent each property. We also have vector 'y', which contain each of the house price. And lets call y' the y value that our model will predict given matrix X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X = \\begin{vmatrix}\n",
    "7 & 1980 & 15 & 67 & 157 & 5 & 4 \\\\\n",
    "5 & 1996 & 20 & 58 & 513 & 5  & 751\\\\\n",
    "6 & 2010 & 67 & 7 & 6 & 6  & 45637\\\\\n",
    "\\end{vmatrix}$\n",
    "\n",
    "$y = \\begin{vmatrix}\n",
    "15000\\\\\n",
    "30000\\\\\n",
    "10000 \\\\\n",
    "\\end{vmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for predicting the price value is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Xθ = y' $ \n",
    "\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "7 & 1980 & 15 & 67 & 157 & 5 & 4 \\\\\n",
    "5 & 1996 & 20 & 58 & 513 & 5  & 751\\\\\n",
    "6 & 2010 & 67 & 7 & 6 & 6  & 37\\\\\n",
    "\\end{vmatrix}\n",
    "$\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "2\\\\\n",
    "4\\\\\n",
    "6 \\\\\n",
    "10 \\\\\n",
    "26 \\\\\n",
    "1 \\\\\n",
    "50 \\\\\n",
    "\\end{vmatrix}$\n",
    "=\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "12981\\\\\n",
    "59587\\\\\n",
    "10536\\\\\n",
    "\\end{vmatrix}$\n",
    "\n",
    "= $y'$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above example, the weights we have here did a pretty good job. The price we got is quite near the real price. But the second house value is quite off compare to other. From here, the difference is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{vmatrix}\n",
    "12981\\\\\n",
    "59587\\\\\n",
    "10536 \\\\\n",
    "\\end{vmatrix}$\n",
    "-\n",
    "$\\begin{vmatrix}\n",
    "15000\\\\\n",
    "30000\\\\\n",
    "10000 \\\\\n",
    "\\end{vmatrix}$\n",
    "=\n",
    "$\\begin{vmatrix}\n",
    "-2019\\\\\n",
    "29587\\\\\n",
    "536 \\\\\n",
    "\\end{vmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want y' to be as close to y as possible. The ideal would be to make y'-y =0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y'- y = 0 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the square loss function. This indicates how bad or good our model is doing. There are many method to use. In this project, I will use mean root square error(RMSE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*9hQVcasuwx5ddq_s3MFCyw.gif\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE from above example is 17084.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Start finding optimal weights</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use normal equation to help finding line that minimize the error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where θ is a vector contain weights for each of the property. The weights inside can be initialize to any value. The only condition is that each number are unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$θ=(X^TX)^-1 X^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $X$ is features matrix, $X^T$ is transpose of $X$. and $y$ is real output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we only use this equation, we might run into a problem called overfitting. Overfitting occurs when a model is excessively complex, such as having too many parameters relative to the number of observations. This can make our model not so accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to avoid overfitting in Linear Regression is to make sure that each of the wieghts is not too high. So we have to come up with the equations that will have small weights and have small error. The formula that can do this is.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$θ=(X^TX+λ⋅L)^-1 −1X^Ty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce a new term called lambda ($λ$). I will skip the prove that term can make the model become less overfit. The value of lambda depends on the problem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Steps</h3>\n",
    "Many of these steps in the formula can be done in parallel. \n",
    "For example when transposing $X$, we can divide X into 4 parts. Then we transpose the 4 parts with 4 processors. \n",
    "\n",
    "Another operations that we can do in parallel is multiplication. Because when multiply, each of the answer cell is independent to each other. \n",
    "\n",
    "In addition, addition is also applicable to parallel processing. Similar to multiplication, each cell in addition is not dependent to each other. \n",
    "\n",
    "More detail can be find in the next part \"Implementation\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Implementation</h3>\n",
    "<h4>The main class for this project are :</h4>\n",
    "<h5>Sequential Version : </h5>\n",
    "<ol>\n",
    "<li>CSV_Reader.java : Read .csv files into Java Matrix.</li>\n",
    "<li>LinearRegression.java : Compute an optimal line using Normal Equation (with regularization ($λ$) )</li>\n",
    "</ol>\n",
    "\n",
    "<h5>Parallel Version : </h5>\n",
    "<ol>\n",
    "<li>P_CSV_Reader.java : Read .csv files into Java Matrix simultaneously.</li>\n",
    "<li>P_LinearRegression.java : Compute an optimal line using Normal Equation (with regularization ($λ$) ) using Threads</li>\n",
    "<li>Thread* : Thread for each task specify by the name. For example ThreadTransposer handle transposing matrix</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>These are some operation that can be done in parallel.</h3>\n",
    "Below are some example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Matrix Multiplication can be done this way in parallel.\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "1 & 1 & 1 & 1 & 1 & 1 & 1 \\\\\n",
    "2 & 2 & 2 & 2 & 2 & 2  & 2\\\\\n",
    "3 & 3 & 3 & 3 & 3 & 3  & 3\\\\\n",
    "4 & 4 & 4 & 4 & 4 & 4 & 4 \\\\\n",
    "1 & 1 & 1 & 1 & 1 & 1  & 1\\\\\n",
    "2 & 2 & 2 & 2 & 2 & 2  & 2\\\\\n",
    "\\end{vmatrix}\n",
    "$\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "X & X & X & X & X  \\\\\n",
    "X & X & X & X & X   \\\\\n",
    "X & X & X & X & X   \\\\\n",
    "X & X & X & X & X   \\\\\n",
    "X & X & X & X & X   \\\\\n",
    "X & X & X & X & X    \\\\\n",
    "X & X & X & X & X   \\\\\n",
    "\\end{vmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number i in Matrix represent which process is handling the multiplication . Because we don't need to write anything into the operand Matrix, we can multiply each of them at the same time. \n",
    "\n",
    "Matrix multiplication is very important because many operation in this method is done by Matrix Multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Transpose Martix\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "11 & 12 & 13 & 14 & 15 & 16 & 17 \\\\\n",
    "21 & 22 & 23 & 24 & 25 & 26  & 27\\\\\n",
    "31 & 32 & 33 & 34 & 35 & 36  & 37\\\\\n",
    "41 & 42 & 43 & 44 & 45 & 46 & 47\\\\\n",
    "51 & 52 & 53 & 54 & 55 & 56  & 57\\\\\n",
    "61 & 62 & 63 & 64 & 65 & 66  & 67\\\\\n",
    "\\end{vmatrix}\n",
    "$\n",
    "=\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "11 & 21 & 31 & 41 & 51 &61  \\\\\n",
    "12 & 22 & 32 & 42 & 52 &62  \\\\\n",
    "13 & 23& 33 & 43 & 53 &63  \\\\\n",
    "14 & 24& 34 & 44 & 54 &64  \\\\\n",
    "15 & 25& 35 & 45 & 55&65   \\\\\n",
    "16 & 26& 36 & 46 & 56 &66  \\\\\n",
    "17 & 27& 37 & 47 & 57  &67 \\\\\n",
    "\\end{vmatrix}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trnaposing is quite easy. Just use each process to handle copying ij if i%4==r where r is number of that process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Reading csv files.\n",
    "In Java, you can't skip over to certain line. So even if you use 4 threads to read a file, the time will be the same. It might be even slower because all of the 4 threads still need to read through everything. \n",
    "\n",
    "In this project I use 4 .csv files instead. So that each of the process can read each of the files in parallel version while in Sequential, you will need to read all of the files by itself alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Done</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>After finish the calculation on the formula above, we will obtain optimal weights for our model. Next step is to evaluate the performance of that weights</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation using validate set</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Xθ = y' $ \n",
    "\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "7 & 1980 & 15 & 67 & 157 & 5 & 4 \\\\\n",
    "5 & 1996 & 20 & 58 & 513 & 5  & 751\\\\\n",
    "6 & 2010 & 67 & 7 & 6 & 6  & 37\\\\\n",
    "7 & 1980 & 15 & 67 & 157 & 5 & 4 \\\\\n",
    "5 & 1996 & 20 & 58 & 513 & 5  & 751\\\\\n",
    "6 & 2010 & 67 & 7 & 6 & 6  & 37\\\\7 & 1980 & 15 & 67 & 157 & 5 & 4 \\\\\n",
    "5 & 1996 & 20 & 58 & 513 & 5  & 751\\\\\n",
    "6 & 2010 & 67 & 7 & 6 & 6  & 37\\\\\n",
    "\\end{vmatrix}\n",
    "$\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "5\\\\\n",
    "1\\\\\n",
    "2 \\\\\n",
    "15 \\\\\n",
    "7 \\\\\n",
    "1.6 \\\\\n",
    "5 \\\\\n",
    "\\end{vmatrix}$\n",
    "=\n",
    "$\n",
    "\\begin{vmatrix}\n",
    "12981\\\\\n",
    "59587\\\\\n",
    "10536\\\\\n",
    "12981\\\\\n",
    "59587\\\\\n",
    "10536\\\\\n",
    "12981\\\\\n",
    "59587\\\\\n",
    "10536\\\\\n",
    "\\end{vmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, we will substituate X, θ, and y to find Root mean square error. When predicting, we can also use parallel processing to compute the answer. For example, we can seperate X into 4 parts, and then multiply each part to $θ$. If the error is high, then you might want to change some parameters.\n",
    "\n",
    "That's all for fitting a best fit line into a data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Results</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the result, I will run each of the algorithm (sequential and parallel) 10 times, then also average them.\n",
    "The version I will demonstrate will be:\n",
    "<ol>\n",
    "<li>Sequential Version</li>\n",
    "<li>Parallel Version (1 thread)</li>\n",
    "<li>Parallel Version (2 thread)</li>\n",
    "<li>Parallel Version (4 thread)</li>\n",
    "</ol>\n",
    "Hopefully, the time need will be decrease if we use more thread. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result can be shown below (with 800,000 number of rows) : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://i.imgur.com/yPygrwJ.jpg\"  width=\"1000\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the Sequential version and the parallel version with 1 threads time is similar. \n",
    "And as the threads increase, the time used is decreased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyyUnKDMzy6X/HwnluR8iKer+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f75144f240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# data to plot\n",
    "n_groups = 3\n",
    "readTime = (901.3,559.3,376.1)\n",
    "trainTime = (696.7,468.9,400.0)\n",
    "totalTime = (1598.0,1028.4,780.3)\n",
    " \n",
    "# create plot\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.25\n",
    "opacity = 0.8\n",
    " \n",
    "rects1 = plt.bar(index, readTime, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 \n",
    "                 label='Reading Time')\n",
    " \n",
    "rects2 = plt.bar(index + bar_width, trainTime, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 \n",
    "                 label='Training Time')\n",
    "\n",
    "rects3 = plt.bar(index + 2*bar_width, totalTime, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 \n",
    "                 label='Total Time')\n",
    " \n",
    "plt.xlabel('Versions')\n",
    "plt.ylabel('Time used')\n",
    "plt.title('Linear Regression Result')\n",
    "plt.xticks(index + bar_width, ('Sequential', 'Parallel (2)', 'Parallel (4)'))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Result</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the time for reading, training, and total time has been reduced because we introduced parallel processing to machine learning model. With more data, the time we can save might be even more. \n",
    "\n",
    "For the predicted answer, the result error is quite near to each other, which is about 190,000. \n",
    "\n",
    "Comparing to the result we can obtain from program called 'RapidMiner'. For ten thousand rows of data, the root mean square error is 736489.\n",
    "\n",
    "Not only in Linear Regression, parallel processing can also be used in many other machine learning model. It can even be used in deep learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusion</h2>\n",
    "<p>In this experiment, we have successfully implement Linear Regression with some parallel processing technique. The result is as shown in the graph above. The time it takes for each version is gradually decrease. If we have larger dataset, the time we saved using parallel might even be larger.</p>\n",
    "\n",
    "<p>This prove to us that parallel computing can be applied in many field, inclusing machine learning. It can improved computation speed and thus reduced time need to compute something. </p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
